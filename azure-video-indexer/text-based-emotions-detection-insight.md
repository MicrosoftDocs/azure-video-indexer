---
title: Get text-based emotion detection insights in Azure AI Video Indexer
description: Text-based emotion detection helps you analyze the emotional tone of video transcripts in Azure AI Video Indexer. Learn how to get insights now.
author: bandersmsft
ms.author: banders
ms.collection: ce-skilling-ai-copilot
ms.date: 06/09/2025
ms.service: azure-video-indexer
ms.topic: how-to
#customer intent: As an Azure user, I want to use text-based emotion detection in Azure AI Video Indexer so that I can analyze the emotional tone of video transcripts.
---

# Get text-based emotion detection insights

Emotion detection finds emotions in a video's transcript lines. Each sentence is detected as *anger*, *fear*, *joy*, *sad*, or *none* if no other emotion is found.

> [!IMPORTANT]
> The model works on text only (labeling emotions in video transcripts.) This model doesn't infer the emotional state of people. So, it might not perform where input is ambiguous or unclear, like sarcastic remarks. **So, the model shouldn't be used for things like assessing employee performance or the emotional state of a person**.

## Text-based emotion detection use cases

- **Content creators and video editors** - Content creators and video editors can use the system to analyze the emotions expressed in the text transcripts of their videos. The analysis helps them gain insights into the emotional tone of their content, allowing them to fine-tune the narrative, adjust pacing, or ensure the intended emotional effect on the audience.
- **Media analysts and researchers** - Media analysts and researchers can employ the system to analyze the emotional content of a large volume of video transcripts quickly. They can use the emotional timeline generated by the system to identify trends, patterns, or emotional responses in specific topics or areas of interest.
- **Marketing and advertising professionals** - Marketing and advertising professionals can utilize the system to assess the emotional reception of their campaigns or video advertisements. Understanding the emotions evoked by their content helps them tailor messages more effectively and to gauge the success of their campaigns.
- **Video consumers and viewers** - End-users, such as viewers or consumers of video content, can benefit from the system by understanding the emotional context of videos without having to watch them entirely. It's useful for users who want to decide if a video is worth watching or for people with limited time to spare.
- **Entertainment industry professionals** - Professionals in the entertainment industry, such as movie producers or directors, can utilize the system to gauge the emotional effect of their film scripts or storylines, aiding in script refinement and audience engagement.

> [!NOTE]
> Text-based emotion detection is language independent. However, if the transcript isn't in English, it's first being translated to English. Only then the model is applied. It might cause a reduced accuracy in emotions detection for non English languages.

## View the insight JSON with the web portal

After you upload and index a video, download insights in JSON format from the web portal.

1. Select the **Library** tab.
1. Select the media you want.
1. Select **Download**, and then select **Insights (JSON)**. The JSON file opens in a new browser tab.
1. Find the key pair described in the example response.

## Use the API

1. Use a [Get Video Index](https://api-portal.videoindexer.ai/api-details#api=Operations&operation=Get-Video-Index) request. Pass `&includeSummarizedInsights=false`.
2. Find the key pairs described in the example response.

## Example response

```json
"emotions": [
  {
    "id": 1,
    "type": "Sad",
    "instances": [
      {
        "confidence": 0.5518,
        "adjustedStart": "0:00:00",
        "adjustedEnd": "0:00:05.75",
        "start": "0:00:00",
        "end": "0:00:05.75"
      }
```

> [!IMPORTANT]
> Read the [transparency note overview](/legal/azure-video-indexer/transparency-note?context=/azure/azure-video-indexer/context/context) for all VI features. Each insight also has its own transparency note.

[!INCLUDE [transparency-text-based-emotion-detection](includes/transparency-text-based-emotion-detection.md)]

## Sample code

[See all samples for VI](https://github.com/Azure-Samples/azure-video-indexer-samples)

## Related content

- [Azure AI Video Indexer documentation](index.yml)